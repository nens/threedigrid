"""
Parse (binary) files generated by make_grid and output the data in various
forms.
"""

import collections
import glob
import logging
import math
import os
from osgeo import ogr, osr

import numpy as np
from osgeo import gdal
from pyproj import transform

from threedi_utils import gis
from threedi_utils.coordinates import get_spatial_reference

from python_flow.grid_tools.exceptions import NotConsistentException

logger = logging.getLogger(__name__)

DATASOURCE_FIELD_TYPE = {
    'int': ogr.OFTInteger,
    'str': ogr.OFTString,
    'real': ogr.OFTReal,
}


# A dict of the files that are read using the corresponding pattern
FILE_PATTERNS = {
    'gridadmin': 'gridadmin'
}

# map the node types to boolean attributes
DIM_MAP = {
    '1d': 'has_onedee',
    '2d': 'has_twodee',
    '2db': 'has_twodee',
    '2demb': 'has_twodee',
}


def angle_degrees(x0, y0, x1, y1):
    """
    return angle between coordinate 0 and 1
    """
    dy = y1 - y0
    dx = x1 - x0
    if dx == 0:
        if dy >= 0:
            return 90
        else:
            return -90
    return math.degrees(math.atan(dy / dx))


def get_file_path(data_path, pattern):
    """ Find the right file using a pattern. Return None if nothing found

    """
    logger.debug("Searching path[%s] for [%s]..." % (data_path, pattern))
    pattern_path = os.path.join(data_path, pattern)
    files = glob.glob(pattern_path)
    if not files:
        logger.debug("Found nothing.")
        return None
    file_path = files[0]  # for now, just take the first
    logger.debug("Found path [%s]." % file_path)
    # make sure this is a file and not dir and there is only one
    # try:
    #     assert len(files) == 1
    #     assert os.path.isfile(file_path)
    # except AssertionError:
    #     # raise Exception("Can't find file using the pattern")
    #     file_path = None
    if len(files) > 1:
        logger.debug(
            "get_file_path:: multiple matching files found, took [%s]" %
            file_path)
    return file_path


def parse_record_array(record_arr):
    b = record_arr[0]
    # b.tolist()
    c = dict(zip(b.dtype.names, b))
    return c


def c_to_f_array(c_array):
    """convert c array to fortran array (transpose ordering)"""
    f_array = np.reshape(c_array.ravel(), c_array.shape[::-1], order='F')
    return f_array


def f_to_c_dims(dimension):
    """in: fortran dimension (tuple), out: c dimension"""
    return dimension[::-1]  # just reverses tuple for now...


class FileParser(object):
    """Let grid parsers subclass this so to get the parsed file you can use the
       FileParser.data property"""

    def __init__(self):
        self._data = self.parse()

    @property
    def data(self):
        return self._data

    def parse(self):
        """The parser and parsing rules"""
        raise NotImplementedError




class GridAdmin(FileParser):
    """
    Reads the gridadministration of the calculation core from its binary files.
    Also presents this adminstration in a dictionary form.
    """

    def __init__(
            self, data_path=None,
            file_pattern='gridadmin_k=??_l=???_i=??????_j=??????.???,???',
            file_path=None, byte_order='<', epsg_code=28992,
            id_mapping=None,
            *args, **kwargs):
        """
        Provide file_path if the full file path is known.

        Alternatively, provide data path and the class will look for a
        gridadmin file.
        """
        self.data_path = data_path
        self.file_pattern = file_pattern
        self.file_path = file_path if file_path else \
            get_file_path(self.data_path, self.file_pattern)
        # endiness of the file; default little endian ('<') for intel
        self.byte_order = byte_order
        self.has_onedee = False  # not known yet
        self.has_twodee = False  # not known yet
        if self.file_path:
            # init, go read the file
            super(GridAdmin, self).__init__()
            self.prepare_node_map()
            self.prepare_nod_line_types()
            self.prepare_node_channel_map()
            self.prepare_node_attributes()
            self.prepare_line_attributes()
        else:
            logger.debug("No file_path, doing nothing.")
        # epsg_code is the epsg code of the coordinates in the grid admin file
        self.epsg_code = epsg_code  # default RD (28992)
        self.id_mapping = id_mapping

    @classmethod
    def filename_from_klijgn(cls, k, l, i, j, g, n):
        """
        given the input parameters, this is the corresponding gridadmin file
        k = kmax
        l = lgrmin
        i, j = grid dimensions
        g = grid number
        n = network number
        """
        return 'gridadmin_k=%2d_l=%3d_i=%6d_j=%6d.%3d,%3d' % (
            k, l, i, j, g, n)

    def update_result(self, tmp_result, f, dtype):
        """Helper function for parsing the file and updating results in a
           dict. """
        record_arr = np.fromfile(f, dtype, count=1)
        d = parse_record_array(record_arr)
        tmp_result.update(d)

    def parse(self):
        result = {}
        f = open(self.file_path, 'rb')
        i4 = self.byte_order + 'i4'
        f8 = self.byte_order + 'f8'
        # int_1d = (i4, (1,))
        # int_2d = (i4, (2, 2))
        dt = np.dtype([
            ('imax', i4),
            ('jmax', i4),
            ('lgrmin', i4),
            ('kmax', i4),
        ])
        self.update_result(result, f, dt)

        dt = np.dtype([
            ('check5', i4),
        ])
        self.update_result(result, f, dt)
        if result['check5'] != 5:
            raise NotConsistentException("5")

        dim1 = f_to_c_dims((result['kmax'],))
        dt = np.dtype([
            ('mmax', (i4, dim1)),
            ('nmax', (i4, dim1)),
        ])
        self.update_result(result, f, dt)

        dt = np.dtype([
            ('nodtot', i4),
            ('nodobc', i4),
            ('nob2d',  i4),
            ('nodall', i4),
            ('n2dtot', i4),
            ('n2dobc', i4),
            ('n1dtot', i4),
            ('n1dobc', i4),
            ('lintot', i4),
            ('linall', i4),
            ('liutot', i4),
            ('livtot', i4),
            ('levnms', i4),
            ('infl1d', i4),
            ('check10', i4),
        ])
        self.update_result(result, f, dt)

        assert result['check10'] == 10
        if result['check10'] != 10:
            raise NotConsistentException("10")

        dim1 = f_to_c_dims((result['linall'], 2))
        dim2 = f_to_c_dims((max(result['nodobc'], 1), 3))
        dt = np.dtype([
            ('line', (i4, dim1)),
            ('linb', (i4, dim2)),
        ])
        self.update_result(result, f, dt)
        if result['nob2d'] == 0:
            result['kt2dobc'] = np.ndarray([0, ])
            result['xyobc'] = np.ndarray([0, ])
        else:
            dim1 = f_to_c_dims((result['nob2d'] + 1,))
            dim2 = f_to_c_dims((result['nob2d'] + 1, 2))
            dt = np.dtype([
                ('kt2dobc', (i4, dim1)),
                ('xyobc', (f8, dim2)),
            ])
            self.update_result(result, f, dt)

        dt = np.dtype([
            ('check20', i4),
        ])
        self.update_result(result, f, dt)

        assert result['check20'] == 20
        if result['check20'] != 20:
            raise NotConsistentException("20")

        dim1 = f_to_c_dims((result['nodall'],))
        dim2 = f_to_c_dims((result['linall'],))
        dim3 = f_to_c_dims((result['linall'], 2))
        dim4 = f_to_c_dims((result['nodtot'],))
        dim5 = f_to_c_dims((4 * result['n2dtot'],))
        dim6 = f_to_c_dims((result['kmax'], result['mmax'][0], 4))
        dim7 = f_to_c_dims((result['kmax'], result['nmax'][0], 4))
        dt = np.dtype([
            ('nodk', (i4, dim1)),
            ('nodm', (i4, dim1)),
            ('nodn', (i4, dim1)),
            ('check30', i4),
            ('lik', (i4, dim2)),
            ('lim', (i4, dim2)),
            ('lin', (i4, dim2)),
            ('check40', i4),
            ('mxautb', (i4, dim3)),
            ('mxvltb', (i4, dim4)),
            ('ksq', (i4, dim5)),
            ('mxvqtb', (i4, dim5)),
            ('mxsqtb', (i4, dim5)),
            ('kcu', (i4, dim2)),
            ('jap1d', i4),
            ('japor', i4),
            ('ip', (i4, dim6)),
            ('jp', (i4, dim7)),
            ('dxp', (f8)),
            ('x0p', (f8)),
            ('y0p', (f8)),
            ('check50', i4),
        ])
        self.update_result(result, f, dt)
        assert result['check30'] == 30
        assert result['check40'] == 40
        assert result['check50'] == 50
        if result['check30'] != 30:
            raise NotConsistentException("30")
        if result['check40'] != 40:
            raise NotConsistentException("40")
        if result['check50'] != 50:
            raise NotConsistentException("50")

        if result['jap1d'] == 0:
            result['nodp1d'] = np.ndarray([0, ])
            result['p1dtyp'] = np.ndarray([0, ])
        else:
            dim1 = f_to_c_dims((result['jap1d'] + 1, 2))
            dim2 = f_to_c_dims((result['jap1d'] + 1,))
            dt = np.dtype([
                ('nodp1d', (i4, dim1)),
                ('p1dtyp', (i4, dim2)),
            ])
            self.update_result(result, f, dt)
        # parse ls, lv, lu and put in lists
        ls = range(result['kmax'])
        lv = range(result['kmax'])
        lu = range(result['kmax'])
        for k in xrange(result['kmax']):
            # Got to add +1 for everything because the Fortran indices for
            # this write start at 0!
            lsdim = f_to_c_dims((result['mmax'][k] + 2, result['nmax'][k] + 2))
            ludim = f_to_c_dims((result['mmax'][k] + 1, result['nmax'][k] + 1))
            lvdim = f_to_c_dims((result['mmax'][k] + 1, result['nmax'][k] + 1))
            dt = np.dtype([
                ('mn_ls', (i4, lsdim)),
                ('check60_%d' % k, i4),
                ('mn_lu', (i4, ludim)),
                ('check70_%d' % k, i4),
                ('mn_lv', (i4, lvdim)),
                ('check80_%d' % k, i4),
            ])
            self.update_result(result, f, dt)
            ls[k] = result['mn_ls']
            lv[k] = result['mn_lv']
            lu[k] = result['mn_lu']

            assert result['check60_%d' % k] == 60
            assert result['check70_%d' % k] == 70
            assert result['check80_%d' % k] == 80
            if result['check60_%d' % k] != 60:
                raise NotConsistentException("60")
            if result['check70_%d' % k] != 70:
                raise NotConsistentException("70")
            if result['check80_%d' % k] != 80:
                raise NotConsistentException("80")

        # NOTE: resulting arrays are already good, no need to convert to
        # Fortran arrays
        result.update({'ls': ls, 'lu': lu, 'lv': lv})

        dim1 = f_to_c_dims((result['nodall'] + 1,))
        dim2 = f_to_c_dims((4, result['n2dtot'] + result['n2dobc'] + 1))
        dt = np.dtype([
            ('xz', (f8, dim1)),
            ('yz', (f8, dim1)),
            ('xbnd', (f8, dim2)),
            ('ybnd', (f8, dim2)),
        ])
        self.update_result(result, f, dt)

        if result['levnms'] == 0:
            result['llev'] = np.ndarray([0, ])
            result['levl'] = np.ndarray([0, ])
            result['levmat'] = np.ndarray([0, ])
            result['levbr'] = np.ndarray([0, ])
        else:
            dim1 = f_to_c_dims((result['infl1d'],))
            dim2 = f_to_c_dims((result['levnms'],))
            dt = np.dtype([
                ('llev', (i4, dim1)),
                ('levl', (i4, dim2)),
                ('levmat', (i4, dim2)),
                ('levbr', (f8, dim2))
            ])
            self.update_result(result, f, dt)

        # only read if there is 1D
        dim1 = f_to_c_dims((result['kmax'],))
        dt = np.dtype([
            ('dx', (f8, dim1)),
            ('l2dtot', i4),
            ('netw1d', i4),
            ('l1dtot', i4),
        ])
        self.update_result(result, f, dt)

        # only read if there is 1D
        dt = np.dtype([
            ('n1dend', i4),  # number of 1D non-shared nodes
            ('k1dtot', i4),  # number of open 1D channels (noc = 1..k1dtot)
            ('k1dmax', i4),  # the max number of points in a channel
        ])
        self.update_result(result, f, dt)

        dt = np.dtype([
            ('check90', i4),
        ])
        self.update_result(result, f, dt)
        if result['check90'] != 90:
            raise NotConsistentException("90, got %d instead" %
                                         result['check90'])
        # if dimensions of a certain array are zero,
        # we set dummy array to avoid absence of variables
        if result['n1dend'] == 0:
            result['nrs1d'] = np.ndarray([0, ])
        else:
            dim1 = f_to_c_dims((result['n1dend'],))
            dt = np.dtype([
                ('nrs1d', (i4, dim1))
            ])
            self.update_result(result, f, dt)

        # if dimensions of a certain array are zero,
        # we set dummy array to avoid absence of variables
        if result['k1dtot'] == 0:
            result['n1dchn'] = np.ndarray([0, ])
        else:
            dim2 = f_to_c_dims((result['k1dtot'],))
            dt = np.dtype([
                ('n1dchn', (i4, dim2))     # number of channel nodes per noc
                ])
            self.update_result(result, f, dt)

        # if dimensions of a certain array are zero,
        # we set dummy array to avoid absence of variables
        if result['k1dtot'] == 0 and result['k1dmax'] == 0:
            result['x1dch'] = np.ndarray([0, 3])
            result['y1dch'] = np.ndarray([0, 3])
            result['nod1d'] = np.ndarray([0, 3])
        else:
            dim3 = f_to_c_dims((result['k1dtot'], result['k1dmax'] + 1))
            # x,y per noc (use n1dchn to determine number of nodes, first
            # column is to be ignored)
            # map back noc and channel point to node
            # nod1d(noc,n), where n=1..n1dchn(noc)
            dt = np.dtype([
                ('x1dch', (f8, dim3)),
                ('y1dch', (f8, dim3)),
                ('nod1d', (i4, dim3)),
            ])
            self.update_result(result, f, dt)

        dt = np.dtype([
            ('check100', i4),
        ])
        self.update_result(result, f, dt)
        if result['check100'] != 100:
            raise NotConsistentException("100")

        # This assert doesn't always work (maybe make_grid keeps open file?)
        # assert f.tell() == os.stat(self.file_path).st_size
        if f.tell() != os.stat(self.file_path).st_size:
            raise NotConsistentException(
                "f.fill [%d] != os.stat [%d]" % (
                    f.tell(), os.stat(self.file_path).st_size))

        # Convert imported c arrays back to fortran arrays
        for k, arr in result.items():
            if k not in ['ls', 'lu', 'lv'] and np.ndim(arr) > 0:
                result[k] = c_to_f_array(arr)

        # TODO: lim and lin have some postprocessing applied to them in
        # read_grid_admin.f90

        f.close()

        return result

    def get_nodes_within_radius(self, node_type, center_pnt, radius):
        """
        returns all 1D or 2D nodes that are within the radius from center_pnt

        :param node_type: either '1d' or '2d'
        :param center_pnt: object with x and y attribute.
        :param radius: radius to search for nodes
        """

        Coords = collections.namedtuple("Coords", 'x, y, area')

        allowed_node_types = ('1d', '2d')
        if node_type not in allowed_node_types:
            logger.error(
                "[-] node_type must be either %s or %s" % allowed_node_types
            )
            return

        nodes_within = {}
        for k, v in self.node_attributes.iteritems():
            t = v['type']
            # looking for a specific node type
            if t != node_type:
                continue
            # N.B. nod2coords is 0 based!
            null_based_node_idx = k-1
            node_coords = Coords(*self.nod2coords(null_based_node_idx))
            dist = gis.get_euclidean_distance(
                center_pnt.x, center_pnt.y, node_coords.x, node_coords.y
            )
            if dist < radius:
                nodes_within[k] = v
        return nodes_within

    def prepare_nod_line_types(self):
        """Prepare node and linetypes for each index"""
        self.nod_types = {}
        for nod_idx in xrange(self.data['nodall']):
            self.nod_types[nod_idx] = self.nod_type_(nod_idx)

        self.line_types = {}
        for line_idx in xrange(self.data['linall']):
            self.line_types[line_idx] = self.line_type_(line_idx)

        self.line_angles = []  # different than line_types, this one is an arr
        self.not_used_wind_lines = []
        self.used_wind_lines = []
        for line_idx in xrange(self.data['linall']):
            angle, used_for_wind = self.line_angle_(line_idx)
            self.line_angles.append(angle)
            if used_for_wind:
                self.used_wind_lines.append(line_idx)
            else:
                self.not_used_wind_lines.append(line_idx)

    def nod_type_(self, nod_idx):
        """calculate node type"""
        n2dtot = self.data['n2dtot']
        n1dtot = self.data['n1dtot']
        n2dobc = self.data['n2dobc']
        n1dobc = self.data['n1dobc']
        if (nod_idx >= 0 and nod_idx < n2dtot):  # 2d
            return '2d'
        elif (nod_idx >= n2dtot and nod_idx < n2dtot + n1dtot):  # 1d
            return '1d'
        elif (nod_idx >= n2dtot + n1dtot and
              nod_idx < n2dtot + n1dtot + n2dobc):  # 2d bound
            # 2d node coordinate calculation
            return '2db'
        elif (nod_idx >= n2dtot + n1dtot + n2dobc and
              nod_idx < n2dtot + n1dtot + n2dobc + n1dobc):  # 1d bound
            # 1d node coordinate calculation
            return '1db'
        else:
            raise Exception("invalid nod_idx [%d], max nod_idx=[%d]" % (
                nod_idx, n2dtot + n1dtot + n2dobc + n1dobc - 1))

    def line_type_(self, line_idx):
        """calculate line type, nod_types must be available

        TODO: use kcu[line_idx]
        line[..l2dtot..l2dtot+l1dtot..l2dtot+l1dtot+n2dobc..]
        Some explanation on KCU types. Every flowline has an kcu value
        to distinguish between the type of lines. In threedicore this
        distinguishing will result in the use of different formulation
        for velocities on these lines
        0 - 1D embedded line
        1 - 1D isolated line
        2 - 1D connected line
        3 - 1D long-crested structure
        4 - 1D short-crested structure
        5 - 1D double connected line
        51 - 1D2D connected line (manhole)
        52 - 1D2D connected line (channel)
        53 - 1D2D double connected line (manhole)
        54 - 1D2D double connected line (channel)
        55 - 1D2D connected line possible breach
        56 - 1D2D connected line active breach
        100 - 2D line
        101 - 2D obstacle (levee) line
        """
        l2dtot = self.data['l2dtot']
        l1dtot = self.data['l1dtot']
        n2dobc = self.data['n2dobc']
        linall = self.data['linall']
        kcu = self.data['kcu'][line_idx]

        if kcu >= 100:
            line_type = '2d'
            line_kcu = kcu
        elif kcu >= 50 and kcu <= 60:
            line_type = '1d2d'
            line_kcu = kcu
        elif kcu >= 0 and kcu <= 10:
            line_type = '1d'
            line_kcu = kcu
        elif (line_idx >= l2dtot + l1dtot and
              line_idx < l2dtot + l1dtot + n2dobc):
            line_type = '2db'
            line_kcu = kcu
        elif line_idx < linall:
            line_type = '1db'
            line_kcu = kcu
        else:
            raise Exception("invalid line_idx [%d], max line_idx=[%d]" % (
                line_idx, linall - 1))

        return line_type, line_kcu

    def node_type(self, node_idx):
        nodall = self.data['nodall']
        n2dtot = self.data['n2dtot']
        n1dtot = self.data['n1dtot']
        n2dobc = self.data['n2dobc']

        if (node_idx + 1 in self.node_channel_map) and (node_idx < n2dtot):
            node_type = '2demb'
        elif node_idx < n2dtot:
            node_type = '2d'
        elif node_idx >= n2dtot and node_idx < n2dtot + n1dtot:
            node_type = '1d'
        elif (node_idx >= n2dtot + n1dtot and
              node_idx < n2dtot + n1dtot + n2dobc):
            node_type = '2db'
        elif node_idx < nodall:
            node_type = '1db'

        return node_type

    def prepare_node_channel_map(self):
        """
        Reverse mapping of calculation nodes and 1D channels. For a given
        calculation node it is now known on which channel it lies and which
        point on that channel it represents. Fortran indexing in noc.
        A dictionary of calculation nodes with different channels and a
        tuple of point on channel is made i.e.:
        {49: {1: (1, 1)}}
        """
        nod1d = self.data['nod1d']
        k1dtot = self.data['k1dtot']
        k1dmax = self.data['k1dmax']
        self.node_channel_map = {}
        for noc in xrange(k1dtot):
            for n in xrange(k1dmax + 1):
                node = nod1d[noc, n]
                if node > 0 and node < 100000000:
                    if node not in self.node_channel_map:
                        self.node_channel_map[node] = {}
                    segment = (noc + 1, n)
                    self.node_channel_map[node][noc + 1] = segment

    def prepare_node_map(self):
        """
        Function to make dictionary of calculation node map to input node
        from network file. For every calculation node the dictionary returns
        the node number from the network file if it is present, since some
        calculation nodes are added later and not given by user input.
        """
        nrs1d = self.data['nrs1d']
        n1dend = self.data['n1dend']
        self.node_map = {nrs1d[n]: n + 1 for n in range(n1dend)}

    def get_nrs1d_id_by_connection_node(self, connection_node_id):
        """

        :param connection_node_id: sequence id of the connection node
        :return: ID of the (fortran) calculation node
        """
        try:
            # index start at "0", computation-core IDs aka
            # sequence IDs start at "1" so subtract by "1"
            return self.data['nrs1d'][connection_node_id-1]
        except IndexError:
            logger.exception(
                "[-] Couldn't get node id. The cooresponding connection "
                "node with sequence ID {0} does not exist in the "
                "'data' object.".format(connection_node_id)
            )
            raise

    def line_angle_(self, line_idx):
        """Calculate line angle.
        for 2d there are only horizontal and vertical lines
        2d: [0..liutot..liutot+livtot]
        line_types must be calculated first.
        """
        liutot = self.data['liutot']
        livtot = self.data['livtot']
        line_type, line_kcu = self.line_types[line_idx]
        angle = 0
        used_for_wind = False
        if line_type == '2db' or line_type == '1db' or line_type == '1d2d':
            # not used
            pass
        elif line_type == '2d':
            if line_idx < liutot:
                angle = 0
            elif line_idx >= liutot and line_idx < liutot + livtot:
                angle = 90
            used_for_wind = True
            # else there is something wrong with the administration and we may
            # crash
        elif line_type == '1d':
            # calculate angle between coordinates
            # line_idx is 0-based, nods are 1-based
            nod0_idx, nod1_idx = self.data['line'][line_idx]
            x0, y0, _ = self.nod2coords(nod0_idx - 1)  # 0-based!!
            x1, y1, _ = self.nod2coords(nod1_idx - 1)
            angle = angle_degrees(x0, y0, x1, y1)
            used_for_wind = True

        return angle, used_for_wind

    def nod2coords(self, nod_idx):
        """
        node index to (local) coodinate calculation. 0-based
        [0..n2dtot,      nodes in 2d area
        n2dtot..n2dtot+n1dtot,     nodes in 1d
        n2dtot+n1dtot..n2dtot+n1dtot+n2dobc,    boundary node in 2d
        n2dtot+n1dtot+n2dobc..n2dtot+n1dtot+n2dobc+n1dobc]   bound node in 1d
        """
        nod_type = self.nod_types[nod_idx]
        if nod_type in ['2d', '2db']:
            # 2d node coordinate calculation
            dx_all = self.data['dx']
            nodk = self.data['nodk']
            dx = dx_all[nodk[nod_idx] - 1]
            # N.B. data['xz'] and data['yz'] are 1-based!
            x_coord = self.data['xz'][nod_idx + 1]
            y_coord = self.data['yz'][nod_idx + 1]
        elif nod_type in ['1d', '1db', '2demb']:
            # 1d node coordinate calculation
            # N.B. data['xz'] and data['yz'] are 1-based!
            x_coord = self.data['xz'][nod_idx + 1]
            y_coord = self.data['yz'][nod_idx + 1]
            dx = 0  # no size for 1d
        else:
            # error
            n2dtot = self.data['n2dtot']
            n1dtot = self.data['n1dtot']
            n2dobc = self.data['n2dobc']
            n1dobc = self.data['n1dobc']
            nodall = self.data['nodall']
            logger.error(
                "Tried to get coords for nod_idx == [%d] >= %d(nodall) == "
                "%d(calculated)" % (
                    nod_idx, nodall, n2dtot + n1dtot + n2dobc + n1dobc))
            x_coord, y_coord, dx = 0, 0, 0
        return x_coord, y_coord, dx

    def nod2cornercoords(self, nod_idx):
        """
        node index to calculate corner coordinates of grid cell
        """
        nodm = self.data['nodm']
        nodn = self.data['nodn']
        n2dtot = self.data['n2dtot']
        n1dtot = self.data['n1dtot']
        n2dobc = self.data['n2dobc']
        if (
                (nod_idx >= 0 and nod_idx < n2dtot) or  # 2d
                (nod_idx >= n2dtot + n1dtot and
                 nod_idx < n2dtot + n1dtot + n2dobc)
        ):  # 2d bound
            # 2d node coordinate calculation
            dxp = self.data['dxp']
            x0p = self.data['x0p']
            y0p = self.data['y0p']
            nodk = self.data['nodk']
            m = nodm[nod_idx] - 1
            n = nodn[nod_idx] - 1
            ip = self.data['ip']
            jp = self.data['jp']
            x0 = x0p + float(ip[nodk[nod_idx] - 1, m, 0]) * dxp - dxp
            x1 = x0p + float(ip[nodk[nod_idx] - 1, m, 3]) * dxp
            y0 = y0p + float(jp[nodk[nod_idx] - 1, n, 0]) * dxp - dxp
            y1 = y0p + float(jp[nodk[nod_idx] - 1, n, 3]) * dxp
            x_cornercoord = np.array([x0, x1, x1, x0])
            y_cornercoord = np.array([y0, y0, y1, y1])

            return x_cornercoord, y_cornercoord

    def line_coords_(self, kcu, network_channel_id, node_left_data,
                     node_right_data):
        """
        Return x0, y0, x1, y1 coordinates for given nodes. This is more
        difficult than it looks because embedded lines behave differently.
        """
        # TODO: some explanation somewhere (or a link to it) for kcu.
        if kcu >= 100:
            channel_id = 0
            x0 = float(node_left_data['x_coord'][channel_id])
            y0 = float(node_left_data['y_coord'][channel_id])
            x1 = float(node_right_data['x_coord'][channel_id])
            y1 = float(node_right_data['y_coord'][channel_id])
        elif kcu in [51, 52, 53, 54, 55]:
            if node_left_data['type'] in ['2d', '2db', '2demb']:
                channel_id = 0
            else:
                channel_id = network_channel_id
            x0 = float(node_left_data['x_coord'][channel_id])
            y0 = float(node_left_data['y_coord'][channel_id])
            if node_right_data['type'] in ['2d', '2db', '2demb']:
                channel_id = 0
            else:
                channel_id = network_channel_id
            x1 = float(node_right_data['x_coord'][channel_id])
            y1 = float(node_right_data['y_coord'][channel_id])
        else:
            channel_id = network_channel_id
            x0 = float(node_left_data['x_coord'][channel_id])
            y0 = float(node_left_data['y_coord'][channel_id])
            x1 = float(node_right_data['x_coord'][channel_id])
            y1 = float(node_right_data['y_coord'][channel_id])
        return [x0, y0], [x1, y1]

    def prepare_line_attributes(self):
        """
        This function builds a data structure with all relevant information of
        flow links. Information consists of:

            - nodes left and right
            - link type
            - link kcu
            - channel_id (from network file)
            - line coordinates (that depends on embedding properties)

        Requires prepare_node_attributes to have run first.

        Example::

            {1:
                {'kcu': 100, 'node_right': 6, 'type': '2d', 'node_left': 1,
                'network_channel_id': 0}
            }

        """
        linall = self.data['linall']
        lines = self.data['line']
        self.line_attributes = {}
        for l in xrange(linall):
            line_attribute = {}
            line_attribute['node_left'] = lines[l, 0]
            line_attribute['node_right'] = lines[l, 1]
            line_type, line_kcu = self.line_type_(l)
            line_attribute['type'] = line_type
            line_attribute['kcu'] = line_kcu
            if line_type in ['2d', '2db']:
                line_attribute['network_channel_id'] = 0
            elif line_type in ['1d', '1db', '1d2d']:
                line_attribute['network_channel_id'] = self.data['lik'][l]
            else:
                raise Exception("invalid line_type [%s]," % (line_type))
            # add coordinates x0, y0, x1, y1, depending on kcu
            line_attribute['coords_left'], line_attribute['coords_right'] = \
                self.line_coords_(
                    line_kcu,
                    line_attribute['network_channel_id'],
                    self.node_attributes[line_attribute['node_left']],
                    self.node_attributes[line_attribute['node_right']])

            self.line_attributes[l + 1] = line_attribute

    def prepare_node_attributes(self):
        """
        This function builds a datastructure with all relevant information of
        calculation nodes. Information consists of:

            - calculation type
            - node type
            - x-y coordinates
            - channel numbers of all channels on which this point lies
                possible raster coordinates

        Examples::

            {1:
                {'raster_coordinates': [1, 1, 1], 'y_coord': {0: 5.0},
                'dx_cell': 10.0, 'x_coord': {0: 5.0}, 'calculation_type': 500,
                'type': '2d'}
            }
            {35:
                {'y_coord': {1: 2.5}, 'channel_segments': {1: (1, 7)},
                'type': '1d', 'x_coord': {1: 36.874989999999997},
                'calculation_type': 1}
            }

        """
        nodall = self.data['nodall']
        x1dch = self.data['x1dch']
        y1dch = self.data['y1dch']
        nodn = self.data['nodn']
        nodm = self.data['nodm']
        nodk = self.data['nodk']
        self.prepare_node_channel_map()
        self.node_attributes = {}
        for nod in xrange(nodall):
            node_attribute = {}
            node_type = self.node_type(nod)
            node_attribute['type'] = node_type
            if node_type in ['2d', '2db']:
                node_attribute['raster_coordinates'] = [
                    int(nodk[nod]), int(nodm[nod]), int(nodn[nod])
                ]
                x_coord, y_coord, dx = self.nod2coords(nod)
                x_coord_channel = {}
                y_coord_channel = {}
                x_coord_channel[0] = x_coord
                y_coord_channel[0] = y_coord
                node_attribute['x_coord'] = x_coord_channel
                node_attribute['y_coord'] = y_coord_channel
                node_attribute['connection_node_id'] = None
                node_attribute['dx_cell'] = dx
                node_attribute['calculation_type'] = 500
                self._set_model_dimension('2d')

            elif node_type == '2demb':
                node_attribute['raster_coordinates'] = [nodk[nod],
                                                        nodm[nod], nodn[nod]]
                x, y, dx = self.nod2coords(nod)
                node_attribute['dx_cell'] = dx
                channel_segment = self.node_channel_map[nod + 1]
                x_coord_channel = {}
                y_coord_channel = {}
                x_coord_channel[0] = x
                y_coord_channel[0] = y
                for key in channel_segment:
                    x_coord_channel[key] = x1dch[
                        channel_segment[key][0] - 1,
                        channel_segment[key][1]
                    ]
                    y_coord_channel[key] = y1dch[
                        channel_segment[key][0] - 1,
                        channel_segment[key][1]
                    ]
                node_attribute['x_coord'] = x_coord_channel
                node_attribute['y_coord'] = y_coord_channel
                node_attribute['connection_node_id'] = self.node_map.get(
                    nod + 1
                )
                node_attribute['channel_segments'] = channel_segment
                node_attribute['calculation_type'] = 500
                self._set_model_dimension('2d')
                self._set_model_dimension('1d')

            elif node_type in ['1d', '1db']:
                # Sometimes we have an non connected 1D calculation node. This
                # can be a isolated pump. This will be a special case that we
                # have to address later.
                channel_segment = self.node_channel_map.get(nod + 1)
                if channel_segment is None:
                    logger.warning('This calculation node is not connected '
                                   'to any flowlinks. Calculation node '
                                   'is %i. Input connection node is %i',
                                   nod + 1, self.node_map.get(nod + 1))
                    continue
                x_coord_channel = {}
                y_coord_channel = {}
                for key in channel_segment:
                    x_coord_channel[key] = x1dch[
                        channel_segment[key][0] - 1,
                        channel_segment[key][1]
                    ]
                    y_coord_channel[key] = y1dch[
                        channel_segment[key][0] - 1,
                        channel_segment[key][1]
                    ]
                node_attribute['x_coord'] = x_coord_channel
                node_attribute['y_coord'] = y_coord_channel
                node_attribute['connection_node_id'] = self.node_map.get(
                    nod + 1
                )
                node_attribute['calculation_type'] = int(nodk[nod])
                node_attribute['channel_segments'] = channel_segment
                self._set_model_dimension('1d')
            else:
                raise Exception("invalid node_type [%s]," % (node_type))
            self.node_attributes[nod + 1] = node_attribute

    def _set_model_dimension(self, dim):
        """if the model dimension is not yet known, set it"""
        # get the name of the class attribute
        attr_name = DIM_MAP[dim]
        # if the attribute is not yet known, set it
        attr = getattr(self, attr_name)
        if not attr:
            setattr(self, attr_name, True)

    def create_grid1d_shapefile(self, output_lines, output_points, output_pumps,
                                epsg_code=None):
        """
        Create shapefile for 1d elements in grid_admin.

        :param output_lines: output filename for lines shapefile
        :param output_points: output filename for points shapefile
        :param epsg_code: projection epsg_code for the shape files should be
            given. Otherwise default 28992 for RD New

        """
        geomtype = 0
        if epsg_code is None:
            epsg_code = self.epsg_code

        # lines
        driver = ogr.GetDriverByName("ESRI Shapefile")
        if os.path.exists(output_lines):
            logger.info('Replacing %s', output_lines)
            driver.DeleteDataSource(str(output_lines))
        sr = get_spatial_reference(epsg_code)
        data_source = driver.CreateDataSource(output_lines)
        layer = data_source.CreateLayer(
            str(os.path.basename(output_lines)),
            sr,
            geomtype
        )
        layer.CreateField(
            ogr.FieldDefn("link_id", DATASOURCE_FIELD_TYPE['int']))
        layer.CreateField(
            ogr.FieldDefn("node_left", DATASOURCE_FIELD_TYPE['int']))
        layer.CreateField(
            ogr.FieldDefn("node_right", DATASOURCE_FIELD_TYPE['int']))
        layer.CreateField(
            ogr.FieldDefn("kcu", DATASOURCE_FIELD_TYPE['int']))
        layer.CreateField(
            ogr.FieldDefn("type", DATASOURCE_FIELD_TYPE['str']))
        layer.CreateField(
            ogr.FieldDefn("channel_id", DATASOURCE_FIELD_TYPE['int']))
        layer.CreateField(
            ogr.FieldDefn("cont_type", DATASOURCE_FIELD_TYPE['str']))
        layer.CreateField(
            ogr.FieldDefn("cont_pk", DATASOURCE_FIELD_TYPE['int']))
        _definition = layer.GetLayerDefn()

        for line_idx in xrange(self.data['linall']):
            linedata = self.line_attributes[line_idx + 1]
            node_left = int(linedata['node_left'])
            node_right = int(linedata['node_right'])
            node_left_data = self.node_attributes[node_left]
            node_right_data = self.node_attributes[node_right]
            line = ogr.Geometry(ogr.wkbLineString)
            # TODO: some explanation somewhere (or a link to it) for kcu.
            if linedata['kcu'] >= 100:
                channel_id = 0
                x0 = float(node_left_data['x_coord'][channel_id])
                y0 = float(node_left_data['y_coord'][channel_id])
                x1 = float(node_right_data['x_coord'][channel_id])
                y1 = float(node_right_data['y_coord'][channel_id])
            elif linedata['kcu'] in [51, 52, 53, 54, 55]:
                if node_left_data['type'] in ['2d', '2db', '2demb']:
                    channel_id = 0
                else:
                    channel_id = linedata['network_channel_id']
                x0 = float(node_left_data['x_coord'][channel_id])
                y0 = float(node_left_data['y_coord'][channel_id])
                if node_right_data['type'] in ['2d', '2db', '2demb']:
                    channel_id = 0
                else:
                    channel_id = linedata['network_channel_id']
                x1 = float(node_right_data['x_coord'][channel_id])
                y1 = float(node_right_data['y_coord'][channel_id])
            else:
                channel_id = linedata['network_channel_id']
                x0 = float(node_left_data['x_coord'][channel_id])
                y0 = float(node_left_data['y_coord'][channel_id])
                x1 = float(node_right_data['x_coord'][channel_id])
                y1 = float(node_right_data['y_coord'][channel_id])
            line.AddPoint(x0, y0)
            line.AddPoint(x1, y1)
            feature = ogr.Feature(_definition)
            feature.SetGeometry(line)
            network_channel_id = int(linedata['network_channel_id'])
            linedata_type = str(linedata['type'])
            kcu = str(linedata['kcu'])
            feature.SetField("node_left", node_left)
            feature.SetField("node_right", node_right)
            feature.SetField("type", linedata_type)
            feature.SetField("kcu", kcu)
            feature.SetField("link_id", line_idx + 1)
            feature.SetField("channel_id", network_channel_id)
            content_type, content_id = self.id_mapping.line_idx_to_type_sql(
                network_channel_id)
            if content_type:
                feature.SetField("cont_type", str(content_type))
            if content_id is not None:
                feature.SetField("cont_pk", int(content_id))
            layer.CreateFeature(feature)
            feature.Destroy()
        data_source.Destroy()

        # points
        driver = ogr.GetDriverByName("ESRI Shapefile")
        if os.path.exists(output_points):
            logger.info('Replacing %s', output_points)
            driver.DeleteDataSource(str(output_points))
        data_source = driver.CreateDataSource(output_points)
        layer = data_source.CreateLayer(
            str(os.path.basename(output_points)),
            sr,
            geomtype
        )

        layer.CreateField(ogr.FieldDefn("nod_id",
                                        DATASOURCE_FIELD_TYPE['int']))
        layer.CreateField(ogr.FieldDefn("calc", DATASOURCE_FIELD_TYPE['int']))
        layer.CreateField(ogr.FieldDefn("type", DATASOURCE_FIELD_TYPE['str']))
        layer.CreateField(ogr.FieldDefn("con_nod",
                                        DATASOURCE_FIELD_TYPE['int']))
        layer.CreateField(ogr.FieldDefn("con_nod_pk",
                                        DATASOURCE_FIELD_TYPE['int']))
        _definition = layer.GetLayerDefn()

        for node_idx in xrange(self.data['nodall']):

            nodedata = self.node_attributes.get(node_idx + 1)
            if nodedata is None:
                logger.warning('This calculation node is not connected '
                               'to any flowlinks. Calculation node '
                               'is %i. Input connection node is %i',
                               node_idx + 1, self.node_map.get(node_idx + 1))
                continue
            if nodedata['type'] in ['2d', '2demb', '2db']:
                channel = 0
            else:
                channels = nodedata['channel_segments'].keys()
                channel = channels[0]
            point = ogr.Geometry(ogr.wkbPoint)
            x0 = float(nodedata['x_coord'][channel])
            y0 = float(nodedata['y_coord'][channel])
            point.AddPoint(x0, y0)
            feature = ogr.Feature(_definition)
            feature.SetGeometry(point)
            type = str(nodedata['type'])
            calculation_type = int(nodedata['calculation_type'])
            connection_node = nodedata['connection_node_id']
            if connection_node is not None:
                connection_node = int(connection_node)
            feature.SetField("nod_id", node_idx + 1)
            feature.SetField("type", type)
            feature.SetField("calc", calculation_type)
            feature.SetField("con_nod", connection_node)
            connection_node_pk = self.id_mapping.cc_to_sql(
                'v2_connection_nodes', connection_node
            )
            if connection_node_pk is not None:
                feature.SetField("con_nod_pk", int(connection_node_pk))
            layer.CreateFeature(feature)
            feature.Destroy()
        data_source.Destroy()

        driver = ogr.GetDriverByName("ESRI Shapefile")
        if os.path.exists(output_pumps):
            logger.info('Replacing %s', output_pumps)
            driver.DeleteDataSource(str(output_pumps))
        data_source = driver.CreateDataSource(output_pumps)
        layer = data_source.CreateLayer(
            str(os.path.basename(output_pumps)),
            sr,
            geomtype
        )
        layer.CreateField(ogr.FieldDefn("id", DATASOURCE_FIELD_TYPE['int']))
        layer.CreateField(ogr.FieldDefn("node1", DATASOURCE_FIELD_TYPE['int']))
        layer.CreateField(ogr.FieldDefn("node2", DATASOURCE_FIELD_TYPE['int']))
        layer.CreateField(ogr.FieldDefn("type", DATASOURCE_FIELD_TYPE['int']))
        layer.CreateField(
            ogr.FieldDefn("nod1_pk", DATASOURCE_FIELD_TYPE['int'])
        )
        layer.CreateField(
            ogr.FieldDefn("nod2_pk", DATASOURCE_FIELD_TYPE['int'])
        )

        _definition = layer.GetLayerDefn()

        for pump_idx in xrange(self.data['jap1d']):
            conn_node1 = self.data['nodp1d'][pump_idx + 1, 0]
            conn_node2 = self.data['nodp1d'][pump_idx + 1, 1]
            if conn_node2 == 0:
                conn_node2 = conn_node1  # When the pump is an end pump which
                                         # pump out of the system. We create
                                         # a line from and to the same node.
            node1 = self.data['nrs1d'][conn_node1 - 1]
            node2 = self.data['nrs1d'][conn_node2 - 1]
            x0, y0, dx1 = self.nod2coords(node1 - 1)
            x1, y1, dx2 = self.nod2coords(node2 - 1)
            line = ogr.Geometry(ogr.wkbLineString)
            line.AddPoint(x0, y0)
            line.AddPoint(x1, y1)
            type = self.data['p1dtyp'][pump_idx + 1]
            feature = ogr.Feature(_definition)
            feature.SetGeometry(line)
            feature.SetField("id", pump_idx + 1)
            feature.SetField("node1", int(node1))
            feature.SetField("node2", int(node2))
            feature.SetField("type", int(type))
            nod1_pk = self.id_mapping.cc_to_sql(
                'v2_connection_nodes', int(node1)
            )
            nod2_pk = self.id_mapping.cc_to_sql(
                'v2_connection_nodes', int(node2)
            )
            if nod1_pk:
                feature.SetField("nod1_pk", int(nod1_pk))
            if nod2_pk:
                feature.SetField("nod2_pk", int(nod2_pk))
            layer.CreateFeature(feature)
            feature.Destroy()
        data_source.Destroy()

    def create_breach_locations(self, output_breaches, levees, epsg_code=None):
        """
        :param output_breaches: path of the output shape file
        :param levees: a list of levee geometries
        :param epsg_code: epsg_code used for projection of the output file
        """

        v2_breach_map = self.id_mapping.mapping.get('v2_breach')

        if not v2_breach_map: return

        if epsg_code is None:
            epsg_code = self.epsg_code

        sr = get_spatial_reference(epsg_code)

        driver = ogr.GetDriverByName("ESRI Shapefile")
        if os.path.exists(output_breaches):
            logger.info('Replacing %s', output_breaches)
            driver.DeleteDataSource(str(output_breaches))

        data_source = driver.CreateDataSource(output_breaches)
        layer = data_source.CreateLayer(
            os.path.basename("breaches"),
            sr,
            ogr.wkbPoint
        )

        layer.CreateField(ogr.FieldDefn(
            "con_pnt_id", DATASOURCE_FIELD_TYPE['int'])
        )
        layer.CreateField(ogr.FieldDefn(
            "breach_idx", DATASOURCE_FIELD_TYPE['int'])
        )
        _definition = layer.GetLayerDefn()

        for id, breach_idx in v2_breach_map.iteritems():
            flow_line_index = self.data['levl'][breach_idx - 1]
            linedata = self.line_attributes[flow_line_index]
            node_left = int(linedata['node_left'])
            node_right = int(linedata['node_right'])
            flowline_geom = self._get_flowline_geom(node_left, node_right)

            for levee in levees:
                if levee.Intersect(flowline_geom):
                    intersection = levee.Intersection(flowline_geom)
                    feature = ogr.Feature(_definition)
                    feature.SetGeometry(intersection)
                    feature.SetField("con_pnt_id", int(id))
                    feature.SetField("breach_idx", int(breach_idx))
                    layer.CreateFeature(feature)

    def create_levee_shapefile(self, output_dir, epsg_code=None):
        """
        Based on Grid coordinates provide by Makegrid in gridadmin file. This
        function draws a shapefile of cell edges that are closed by a levee.

        :param epsg_code: projection epsg_code for the shape files should be
            given. Otherwise default 28992 for RD New

        """
        data = self.data
        geomtype = 0
        if epsg_code is None:
            epsg_code = self.epsg_code

        driver = ogr.GetDriverByName(b'ESRI Shapefile')
        if os.path.exists(output_dir):
            logger.info('Replacing %s', output_dir)
            driver.DeleteDataSource(str(output_dir))
        sr = get_spatial_reference(epsg_code)
        shape = driver.CreateDataSource(str(output_dir))
        layer = shape.CreateLayer(
            str(os.path.basename(output_dir)),
            sr,
            geomtype
        )
        layer.CreateField(ogr.FieldDefn("line_idx",
                                        DATASOURCE_FIELD_TYPE['int']))

        # add feature

        _definition = layer.GetLayerDefn()

        nodk = self.data['nodk']
        for line_idx in xrange(data['l2dtot']):
            if data['kcu'][line_idx] == 101:
                linedata = self.line_attributes[line_idx + 1]
                node_left = int(linedata['node_left'])
                node_right = int(linedata['node_right'])
                edge = self._get_edge_geom(
                    nodk, node_left=node_left, node_right=node_right
                )
                flowline_geom = self._get_flowline_geom(node_left, node_right)

                for i in xrange(len(edge)):
                    intersect = flowline_geom.Intersect(edge[i])
                    if intersect is True:
                        feature = ogr.Feature(_definition)
                        feature.SetGeometry(edge[i])
                        feature.SetField("line_idx", line_idx + 1)
                        layer.CreateFeature(feature)

    def _get_flowline_geom(self, node_left, node_right):
        """
        get the flowline geometry between node_left and node_right
        :param node_left: index used to look up xy in self.data['xz']
            and self.data['yz']
        :param node_right: index used to look up xy in self.data['xz']
            and self.data['yz']
        """
        flowline = ogr.Geometry(ogr.wkbLineString)
        flowline.AddPoint(
            self.data['xz'][node_left],
            self.data['yz'][node_left]
        )
        flowline.AddPoint(
            self.data['xz'][node_right],
            self.data['yz'][node_right]
        )
        return flowline

    def _get_edge_geom(self, nodk, node_left, node_right):
        """
        get the geom of all edges of a 2d cell
        """

        if nodk[node_left-1] < nodk[node_right-1]:
            nod_idx = node_left
        else:
            nod_idx = node_right

        # All cell edges
        edge = []
        edge.append(ogr.Geometry(ogr.wkbLineString))
        edge[0].AddPoint(
            self.data['xbnd'][0, nod_idx],
            self.data['ybnd'][0, nod_idx]
        )
        edge[0].AddPoint(
            self.data['xbnd'][1, nod_idx],
            self.data['ybnd'][1, nod_idx]
        )

        edge.append(ogr.Geometry(ogr.wkbLineString))
        edge[1].AddPoint(
            self.data['xbnd'][1, nod_idx],
            self.data['ybnd'][1, nod_idx]
        )
        edge[1].AddPoint(
            self.data['xbnd'][2, nod_idx],
            self.data['ybnd'][2, nod_idx]
        )

        edge.append(ogr.Geometry(ogr.wkbLineString))
        edge[2].AddPoint(
            self.data['xbnd'][2, nod_idx],
            self.data['ybnd'][2, nod_idx]
        )
        edge[2].AddPoint(
            self.data['xbnd'][3, nod_idx],
            self.data['ybnd'][3, nod_idx]
        )

        edge.append(ogr.Geometry(ogr.wkbLineString))
        edge[3].AddPoint(
            self.data['xbnd'][3, nod_idx],
            self.data['ybnd'][3, nod_idx]
        )
        edge[3].AddPoint(
            self.data['xbnd'][0, nod_idx],
            self.data['ybnd'][0, nod_idx]
        )

        return edge

    def create_grid_shapefile(self, output_dir, epsg_code=None):
        """
        Based on Grid coordinates provided by Makegrid in gridadmin file, this
        function creates polygons of 2D calculation cells.

        :param epsg_code: projection epsg_code for the shape files should be
            given. Otherwise default 28992 for RD New.

        """
        # data is a dict that must contain: xbnd, ybnd
        data = self.data
        geomtype = 0
        if epsg_code is None:
            epsg_code = self.epsg_code

        driver = ogr.GetDriverByName(b'ESRI Shapefile')
        if os.path.exists(output_dir):
            logger.info('Replacing %s', output_dir)
            driver.DeleteDataSource(str(output_dir))
        sr = get_spatial_reference(epsg_code)
        shape = driver.CreateDataSource(str(output_dir))
        layer = shape.CreateLayer(
            str(os.path.basename(output_dir)),
            sr,
            geomtype
        )
        layer.CreateField(ogr.FieldDefn("nod_idx",
                                        DATASOURCE_FIELD_TYPE['int']))

        # add feature
        _definition = layer.GetLayerDefn()

        n2dall = data['n2dtot'] + data['n2dobc']
        for nod_idx in xrange(n2dall):

            # Create ring
            ring = ogr.Geometry(ogr.wkbLinearRing)
            ring.AddPoint(self.data['xbnd'][0, nod_idx + 1],
                          self.data['ybnd'][0, nod_idx + 1])
            ring.AddPoint(self.data['xbnd'][1, nod_idx + 1],
                          self.data['ybnd'][1, nod_idx + 1])
            ring.AddPoint(self.data['xbnd'][2, nod_idx + 1],
                          self.data['ybnd'][2, nod_idx + 1])
            ring.AddPoint(self.data['xbnd'][3, nod_idx + 1],
                          self.data['ybnd'][3, nod_idx + 1])
            ring.AddPoint(self.data['xbnd'][0, nod_idx + 1],
                          self.data['ybnd'][0, nod_idx + 1])

            # Create polygon from ring
            poly = ogr.Geometry(ogr.wkbPolygon)
            poly.AddGeometry(ring)

            feature = ogr.Feature(_definition)
            feature.SetGeometry(poly)
            if nod_idx < data['n2dtot']:
                feature.SetField("nod_idx", nod_idx + 1)
            else:
                feature.SetField("nod_idx", nod_idx + data['n1dtot'] + 1)
            layer.CreateFeature(feature)

    def create_grid_geotiff(self, output_filename, transform,
                            width, height, epsg_code=None):
        """
        Create a geotiff of the calculation grid. This GTiff is created based
        on data dict from gridadmin file. We need the projection to project is
        on a coordinate system correctly.

        :param epsg_code: projection epsg_code for the shape files should be
            given. Otherwise default 28992 for RD New

        """
        data = self.data
        # NO_DATA = -9999

        if epsg_code is None:
            epsg_code = self.epsg_code
        sr = get_spatial_reference(epsg_code)

        # prepare raster
        raster = np.zeros((height, width), dtype='float32')
        nodm = data['nodm']
        nodn = data['nodn']
        nodk = data['nodk']
        dx = data['dx']
        pixelsize = transform[1]
        logger.debug("pixel size: %f", pixelsize)
        for nod_idx in xrange(data['n2dtot']):
            m = nodm[nod_idx] - 1
            n = nodn[nod_idx] - 1
            size = dx[nodk[nod_idx] - 1] / pixelsize
            raster[n * size:n * size + size,
                   m * size:m * size + size] = nod_idx

        # prepare output file
        driver = gdal.GetDriverByName("GTiff")
        dst_ds = driver.Create(
            output_filename, width, height, 1,
            gdal.GDT_Int32, ['COMPRESS=DEFLATE', ])
        dst_ds.SetGeoTransform(transform)

        # set the reference info
        dst_ds.SetProjection(sr.ExportToWkt())

        # write the band

        # flip upside down for our geotiff
        raster = np.flipud(raster)

        dst_ds.GetRasterBand(1).WriteArray(raster)

    def generate_nod_grid(self, shared_var, pixelsize):
        """
        generate nod grid, a pixel map of all nodes.
        input: shared_var
        result: every pixel contains a nod_idx (hopefully)
        """

        # data is a dict that must contain: nodm, nodn, nodk, dx, kmax, n2dtot
        data = self.data
        nodm = data['nodm']
        nodn = data['nodn']
        nodk = data['nodk']
        dx = data['dx']
        for nod_idx in xrange(data['n2dtot']):
            m = nodm[nod_idx] - 1
            n = nodn[nod_idx] - 1
            size = dx[nodk[nod_idx] - 1] / pixelsize
            shared_var.data[
                n * size:n * size + size,
                m * size:m * size + size] = nod_idx
        # flip upside-down to match geotiff
        shared_var.data = shared_var.data[::-1, ::]

    def generate_2d_nod_locations(self, x0=0, y0=0):
        # nod2coords already does this? But is it the center point?
        result = []
        nodes = range(self.data['n2dtot'])
        for nod_idx in nodes:
            x_coord, y_coord, size = self.nod2coords(nod_idx)
            x_coord += x0
            y_coord += y0
            result.append([nod_idx, x_coord, y_coord])
        return result

    def get_twodee_node_extent(self, source_proj=None, target_proj=None):
        """
        return extent that is spanned by the 2D nodes.
        [y0, x0, y1, x1]

        If source_proj and target_proj are provided, the coordinates are
        transformed into the target_proj. This is done for each coordinate to
        avoid projection issues if doing it after the extent determination!

        :param source_proj (optional) - Proj instance of the projection that is
            used for the node attribute coordinates. If given, also target_proj
            should be given.
        :param target_proj (optional) - Proj instance of the projection that
            is used for converting the node coordinates into. If given, a
            lso source_proj should be given.

        :return the extent of the coordinates of the xbnd and ybnd arrays
            (transformed into the target_proj if both source_proj and
            target_proj are provided).
        """
        # first dim completely, sec dim 1: end
        # self.data['xbnd'] and self.data['ybnd'] might have 0 values
        xbnd_min = self.data['xbnd'][:, 1:].min()
        ybnd_min = self.data['ybnd'][:, 1:].min()
        xbnd_max = self.data['xbnd'][:, 1:].max()
        ybnd_max = self.data['ybnd'][:, 1:].max()
        # transform if source_proj and target_proj are provided
        if source_proj and target_proj:
            xbnd_min, ybnd_min = transform(
                source_proj, target_proj, xbnd_min, ybnd_min)
            xbnd_max, ybnd_max = transform(
                source_proj, target_proj, xbnd_max, ybnd_max)

        return ybnd_min, xbnd_min, ybnd_max, xbnd_max

    def node_extent(self, source_proj=None, target_proj=None):
        """
        return extent that is spanned by the nodes.
        [y0, x0, y1, x1]

        If source_proj and target_proj are provided, the coordinates are
        transformed into the target_proj. This is done for each coordinate to
        avoid projection issues if doing it after the extent determination!

        grid_admin.node_attributes[1000]
        {'calculation_type': -1,
        'y_coord': {486: 436233.0},
        'connection_node_id': 431,
        'x_coord': {486: 86418.559999999998},
        'channel_segments': {486: (486, 2)},
        'type': '1db'}

        :param source_proj (optional) - Proj instance of the projection that is
            used for the node attribute coordinates. If given, also target_proj
            should be given.
        :param target_proj (optional) - Proj instance of the projection that is used for
            converting the node coordinates into. If given, also source_proj
            should be given.

        :return the extent of the coordinates of the node_attributes
            (transformed into the target_proj if both source_proj and
            target_proj are provided).

        """
        x0, y0, x1, y1 = None, None, None, None

        for v in self.node_attributes.values():
            for k, x_v in v['x_coord'].items():
                y_v = v['y_coord'][k]

                # transform if source_proj and target_proj are provided
                if source_proj and target_proj:
                    x_v, y_v = transform(
                        source_proj, target_proj, x_v, y_v)

                # find the lower-left and upper-right coordinates
                if y0 is None or y0 > y_v:
                    y0 = y_v
                if y1 is None or y1 < y_v:
                    y1 = y_v
                if x0 is None or x0 > x_v:
                    x0 = x_v
                if x1 is None or x1 < x_v:
                    x1 = x_v

        # return the extent
        return y0, x0, y1, x1


class GridAdminParser(GridAdmin):
    def __init__(self, *args, **kwargs):
        logger.warning("GridAdminParser is deprecated, use GridAdmin instead.")
        return super(GridAdminParser, self).__init__(*args, **kwargs)
